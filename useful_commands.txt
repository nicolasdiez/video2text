### DEV ###

# create virtual environment
python -m venv video2text-venv

# activate virtual environment
source video2text-venv/Scripts/activate

# freeze project dependencies into file
python -m pip freeze > requirements.txt

# install project dependencies from file
source video2text-venv/Scripts/activate
pip install -r requirements.txt

# generate a requirements based on imports
pipreqs --force --ignore tests --savepath requirements_from_src.txt ./src

# confirm version of ffmpeg installed
ffmpeg -version


### CI/CD - DOCKER ###

# buil, run

# go to runner directoy
cd ~/actions-runner

# build docker image (in project root, where Dockerfile is located)
docker build -t fastapi-app:local .

# run container with docker desktop
docker run -p 8000:8000 fastapi-app:local

# force pull latest remote image from GitHub Container Registry (GHCR) into local environment (before docker run)
docker pull ghcr.io/nicolasdiez/video2text:latest

# run remote image with docker desktop (validate by opening http://localhost:8000/docs)
docker run -p 8000:8000 ghcr.io/nicolasdiez/video2text:latest

# check the docker image I have locally
docker images ghcr.io/nicolasdiez/video2text

# remove the old local latest image
docker rmi ghcr.io/nicolasdiez/video2text:latest

# list all local images
docker images -a

# remove all local images
docker rmi -f $(docker images -aq)

# lista contenedores con nombre, estado y puertos
sudo docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# inspect container
sudo docker inspect CONTAINER_NAME --format '{{.Name}} {{.State.Status}} {{.NetworkSettings.Ports}}'

# stop container from running
sudo docker stop CONTAINER_NAME

# pause container from running (freeze process, without stopping or re-starting)
sudo docker pause CONTAINER_NAME

# resume paused container
sudo docker unpause CONTAINER_NAME


# logs

# see application logs realtime (parar con Ctrl+C)
sudo docker logs -f CONTAINER_NAME

# see last 200 log lines
sudo docker logs --tail 200 CONTAINER_NAME

# edit logger config file (Google Cloud Ops Agent) (Save&Exit: Ctrl+O, Enter, Ctrl+X)
sudo nano /etc/google-cloud-ops-agent/config.yaml


# clean

# clean up all resources
docker system prune -a --volumes

# see docker resources being used
docker system df

# see which directory is docker using
sudo docker info | grep "Docker Root Dir"

# remove all running containers
sudo docker stop $(sudo docker ps -q) 2>/dev/null || true

# remove all running and stopped containers
sudo docker rm -f $(sudo docker ps -aq) 2>/dev/null || true

# verify that no containers are running
sudo docker ps -a




### GITHUB SELF-HOSTED RUNNER (GCP VM) ###

# Run github actions self-hosted runner job in VM
cd actions-runner/
./run.sh

# Ver puertos y conexiones en la VM
sudo ss -tulpen | grep 8000 || sudo netstat -tulpen | grep 8000

# Ver uso CPU / memoria / procesos pesados 
sudo apt install -y procps && top -b -n1 | head -n 20 
ps aux --sort=-%cpu | head -n 20 
ps aux --sort=-%mem | head -n 20

# Liberar caches de página (sync + drop caches) 
sync && echo 3 | sudo tee /proc/sys/vm/drop_caches

# Vaciar swap (forzar mover a RAM y limpiar swap) 
sudo swapoff -a && sudo swapon -a

# Matar procesos con CPU alta (ejemplo: matar procesos >40% CPU) 
ps -eo pid,ppid,cmd,%cpu --sort=-%cpu | awk '$4>40 {print $1}' | xargs -r sudo kill -9

# Liberar caches de apt/paquetes (si hay mucho espacio usado) 
sudo apt-get clean && sudo rm -rf /var/cache/apt/archives/*

# Ver estado de memoria, swap y carga 
free -h; vmstat 1 5; uptime

# Revisar I/O y procesos bloqueantes (instalar: sudo apt install -y iotop) 
sudo iotop -b -n 5 

# Reiniciar servicios problemáticos sin reboot (ejemplo systemd) 
sudo systemctl restart <servicio>

# Reboot si todo lo demás falla (limpieza completa, último recurso) 
sudo reboot

# Limpieza periódica (para no acumular capas)
docker system prune -af
docker builder prune --all --filter until=24h

# Inspect VM specs
CPU summary: 				lscpu
Number of vCPUs (simple): 	nproc
Memory: 					free -h
Detailed memory info:		cat /proc/meminfo | head -n 5
Disk devices and sizes:		lsblk -o NAME,SIZE,TYPE,MOUNTPOINT
Filesystem usage:			df -h
Kernel/architecture:		 uname -a

# Verificar uso de disco y localizar dónde falta espacio
df -h
du -hsx /* 2>/dev/null | sort -rh | head -n 20
du -sh /home/* 2>/dev/null

# Limpiar caché de apt
sudo apt-get clean
sudo rm -rf /var/cache/apt/archives/*

# Limpiar contenedores, imágenes y builders Docker no usados
sudo docker system prune -af 
sudo docker builder prune --all --force 
sudo docker image prune -af

# Borrar images/containers huérfanos y volúmenes grandes
sudo docker volume ls -q | xargs -r sudo docker volume rm

# Liberación específica para actions-runner si tiene sesiones antiguas o carpetas grandes
# Dentro del directorio del runner
du -sh ~/actions-runner/*
# borrar backups o logs viejos
sudo rm -rf ~/actions-runner/_work/*

# Limpiar logs y archivos temporales
# Truncar journal (si ocupa mucho)
sudo journalctl --vacuum-size=100M
# Limpiar /tmp
sudo rm -rf /tmp/*

# Buscar grandes ficheros residuales
find / -xdev -type f -size +100M -exec ls -lh {} \; 2>/dev/null | sort -k5 -h



### UTILS ###

# google cloud console (justfol..)
https://console.cloud.google.com/apis/

# auto-generated swagger by FastAPI (if shown then server is running properly)
http://localhost:8000/docs

# curl test for POST /pipelines/fetch-videos-generate-tweets/run/{channel_id}
curl -X POST "http://localhost:8000/pipelines/fetch-videos-generate-tweets/run/UCJQQVLyM6wtPleV4wFBK06g" -H "Content-Type: application/json" -d '{"prompt_file":"shortsentences-from-transcript.txt","max_videos":1,"max_sentences":2}'

# curl test for POST /pipelines/ingestion/run/{user_id}
curl -X POST "http://localhost:8000/pipelines/ingestion/run/64e8b0f3a1b2c3d4e5f67891" -H "Content-Type: application/json" -d '{"prompt_file":"shortsentences-from-transcript.txt","max_videos":1,"max_tweets":2}'

# curl test for POST /pipelines/publishing/run/{user_id}
curl -X POST "http://localhost:8000/pipelines/publishing/run/64e8b0f3a1b2c3d4e5f67891" -H "Content-Type: application/json" -d '{"max_tweets_to_fetch": 10, "max_tweets_to_publish": 5}'

